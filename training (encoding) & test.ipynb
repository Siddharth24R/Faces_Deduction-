{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade opencv-contrib-python\n",
    "!python -m pip install --upgrade --user pip\n",
    "!pip install opencv-contrib-python\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install opencv-contrib-python\n",
    "!pip install dlib\n",
    "!pip install face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python==4.5.5.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Save Face Encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Encodings saved to 'encodings.npy'.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def train_classifier(siddharth_dir):\n",
    "    known_encodings = []\n",
    "    known_ids = []\n",
    "\n",
    "    # Iterate over images in the directory\n",
    "    for file_name in os.listdir(siddharth_dir):\n",
    "        if file_name.lower().endswith(\".jpg\"):\n",
    "            image_path = os.path.join(siddharth_dir, file_name)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Get face encodings\n",
    "            encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "            if len(encodings) > 0:\n",
    "                \n",
    "                known_encodings.append(encodings[0])\n",
    "                known_ids.append(file_name.split(\".\")[0])  # Use filename as ID or label\n",
    "\n",
    "    # Save the encodings and IDs for later use\n",
    "    np.save(\"encodings.npy\", known_encodings)\n",
    "    np.save(\"ids.npy\", known_ids)\n",
    "\n",
    "    print(\"Training complete. Encodings saved to 'encodings.npy'.\")\n",
    "\n",
    "# Use the specified directory\n",
    "siddharth_dir = r\"C:\\ALL folder in desktop\\PycharmProjects\\face detection\\dataset\\siddharth\"\n",
    "train_classifier(siddharth_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Saved Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_classifier():\n",
    "    known_encodings = np.load(\"encodings.npy\", allow_pickle=True)\n",
    "    known_ids = np.load(\"ids.npy\", allow_pickle=True)\n",
    "    return known_encodings, known_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognize Faces in New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "def recognize_faces(image_path, known_encodings, known_ids):\n",
    "    # Load the image to recognize faces\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "    \n",
    "    # Initialize the list of recognized names\n",
    "    face_names = []\n",
    "\n",
    "    # Loop over each face found in the image\n",
    "    for face_encoding in face_encodings:\n",
    "        # Check if the face matches any known faces\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "        \n",
    "        # If there's a match, get the name of the known face\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_ids[first_match_index]\n",
    "        \n",
    "        face_names.append(name)\n",
    "    \n",
    "    return face_locations, face_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Recognition Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recognition_results(image_path, face_locations, face_names):\n",
    "    # Load the image to display results\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        \n",
    "        # Draw a label with the name below the face\n",
    "        cv2.rectangle(image, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(image, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('Face Recognition', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process All Images in the Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_images(siddharth_dir):\n",
    "    known_encodings, known_ids = load_classifier()\n",
    "\n",
    "    for file_name in os.listdir(siddharth_dir):\n",
    "        if file_name.lower().endswith(\".jpg\"):\n",
    "            image_path = os.path.join(siddharth_dir, file_name)\n",
    "            face_locations, face_names = recognize_faces(image_path, known_encodings, known_ids)\n",
    "            display_recognition_results(image_path, face_locations, face_names)\n",
    "\n",
    "# Process all images in the specified directory\n",
    "process_all_images(siddharth_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n",
      "Face 1 encoding: [-1.28271893e-01  1.30143046e-01  5.90104014e-02 -6.49003498e-03\n",
      " -8.32966790e-02 -3.09673436e-02 -1.79578010e-02 -1.26377359e-01\n",
      "  1.55274585e-01 -1.23240702e-01  3.43255043e-01 -8.55886564e-03\n",
      " -1.62437111e-01 -1.31151363e-01 -2.23334115e-02  2.24700987e-01\n",
      " -1.76634774e-01 -1.13462336e-01 -1.13649666e-01  3.51699814e-03\n",
      "  8.09343234e-02  7.61153968e-03  3.96296568e-02  4.46226727e-03\n",
      " -7.55337477e-02 -3.86382163e-01 -1.09456375e-01 -8.20067525e-02\n",
      "  8.18034410e-02 -3.34783792e-02 -2.52959430e-02 -3.75255346e-02\n",
      " -2.03658774e-01 -7.02132359e-02 -2.80389488e-02  5.98566048e-03\n",
      " -2.34052166e-02 -1.39666907e-03  2.21993431e-01 -4.88245860e-05\n",
      " -2.36875013e-01  7.55943209e-02  8.17102473e-03  2.50395745e-01\n",
      "  1.74542412e-01  2.80301273e-02  4.70339879e-02 -1.16099551e-01\n",
      "  2.75589097e-02 -1.52217239e-01  6.71192259e-02  1.04841813e-01\n",
      "  1.74155891e-01  6.03058971e-02 -8.35879706e-03 -1.00044891e-01\n",
      " -3.30029055e-02  1.04957700e-01 -1.95312813e-01  2.67806463e-04\n",
      "  4.71117944e-02 -4.80026864e-02 -4.16076593e-02 -5.22476211e-02\n",
      "  2.16649771e-01  7.44980648e-02 -1.21436797e-01 -1.37179032e-01\n",
      "  1.44099861e-01 -1.22513160e-01 -4.03948016e-02  6.32195175e-03\n",
      " -1.34490356e-01 -2.09619552e-01 -3.59071314e-01  6.32969886e-02\n",
      "  4.24904913e-01  1.04594775e-01 -2.67303675e-01  4.19660378e-03\n",
      " -6.83887079e-02 -5.30513339e-02  6.67449534e-02  1.20980620e-01\n",
      " -2.39876304e-02  2.18760334e-02 -8.99865404e-02  2.33211517e-02\n",
      "  1.52063951e-01 -9.75013003e-02 -1.87005848e-02  2.50578701e-01\n",
      "  3.72679681e-02  2.80083083e-02  1.11883134e-02  5.98638728e-02\n",
      " -4.23032120e-02  4.50854283e-03 -1.19949162e-01 -1.06777539e-02\n",
      " -8.42921901e-03 -2.53112912e-02 -1.18958484e-02  5.90798706e-02\n",
      " -1.57173648e-01  1.89944655e-01  3.41111086e-02 -1.14428904e-02\n",
      " -1.74384415e-02  4.85200062e-02 -7.52560496e-02 -1.11906335e-01\n",
      "  1.29453406e-01 -1.67414099e-01  2.05027446e-01  2.22203940e-01\n",
      "  1.90288275e-02  1.78293109e-01  1.11392520e-01  1.03832081e-01\n",
      " -2.61597224e-02  1.61123574e-02 -1.72860831e-01 -4.39364053e-02\n",
      "  7.16867223e-02 -3.95511910e-02  1.12410232e-01  6.37126416e-02]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "# Load the image from the specified path\n",
    "image_path = r\"C:\\ALL folder in desktop\\PycharmProjects\\face detection\\dataset\\siddharth\\siddharth_60.jpg\"\n",
    "image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "# Find all face locations in the image\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "# Generate face encodings based on the detected face locations\n",
    "face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "# Print the number of faces detected\n",
    "print(f\"Number of faces detected: {len(face_locations)}\")\n",
    "\n",
    "# Print the face encodings (this is optional)\n",
    "for i, face_encoding in enumerate(face_encodings):\n",
    "    print(f\"Face {i+1} encoding: {face_encoding}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
